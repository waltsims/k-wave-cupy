"""
Minimal N-D k-Wave Python Backend.
Supports 1D, 2D, and 3D k-space pseudospectral wave propagation.

Design: Simulation class with setup/step separation for debuggability.
"""
import numpy as np
from types import SimpleNamespace
try: import cupy as cp
except ImportError: cp = None

# =============================================================================
# Utility Functions
# =============================================================================

# Graceful attribute access for optional MATLAB struct fields
def _attr(obj, name, default=None):
    return getattr(obj, name, default)

# Zero arrays/scalars from MATLAB indicate "disabled" features
def _is_enabled(x):
    return x is not None and not (np.all(x == 0) if hasattr(x, '__len__') else x == 0)

def _to_cpu(x):
    return x.get() if hasattr(x, "get") else x

def _expand_to_grid(val, grid_shape, xp, name="parameter"):
    if val is None: raise ValueError(f"Missing required parameter: {name}")
    arr = xp.array(val, dtype=float).flatten(order="F")
    grid_size = int(np.prod(grid_shape))
    if arr.size == 1: return xp.full(grid_shape, float(arr[0]), dtype=float)
    if arr.size == grid_size: return arr.reshape(grid_shape, order="F")
    raise ValueError(f"{name} size {arr.size} incompatible with grid size {grid_size}")

# =============================================================================
# Simulation Class
# =============================================================================

class Simulation:
    """N-D k-Space Pseudospectral Wave Propagator with setup/step separation.

    Usage:
        sim = Simulation(kgrid, medium, source, sensor)
        sim.setup()                    # Inspect sim.p, sim.op_grad_list, etc.
        sim.step()                     # One time step, inspect fields
        results = sim.run()            # Run remaining steps, return results

    Or simply:
        results = Simulation(kgrid, medium, source, sensor).run()
    """

    def __init__(self, kgrid, medium, source, sensor, backend="auto"):
        self.kgrid = kgrid
        self.medium = medium
        self.source = source
        self.sensor = sensor
        self.xp = cp if cp and backend in ("auto", "gpu") else np
        self._is_setup = False
        self.t = 0  # Current time step

    def setup(self):
        """Initialize operators and fields. Call before step()/run()."""
        xp = self.xp
        print(f"Running on {'CuPy (GPU)' if xp is not np else 'NumPy (CPU)'} backend")

        # Parse grid dimensions
        self.dims, self.spacing = [], []
        for axis in ['x', 'y', 'z']:
            N = _attr(self.kgrid, f'N{axis}', None)
            d = _attr(self.kgrid, f'd{axis}', None)
            if N is not None and d is not None:
                self.dims.append(int(N))
                self.spacing.append(float(d))
            else:
                break

        self.grid_shape = tuple(self.dims)
        self.ndim = len(self.dims)
        self.Nt = int(self.kgrid.Nt)
        self.dt = float(self.kgrid.dt)

        # Medium properties
        self.c0 = _expand_to_grid(self.medium.sound_speed, self.grid_shape, xp, "sound_speed")
        self.rho0 = _expand_to_grid(_attr(self.medium, 'density', 1000.0), self.grid_shape, xp, "density")
        self.c_ref = float(xp.max(self.c0))

        # CFL stability limit for pseudospectral methods on staggered grids:
        # c * dt / dx <= 2/pi / sqrt(ndim)  (Tabei, Mast & Waag, JASA 2002, Eq. 11)
        cfl = self.c_ref * self.dt / min(self.spacing)
        cfl_max = 2 / (np.pi * np.sqrt(self.ndim))
        if cfl > cfl_max: print(f"Warning: Unstable CFL={cfl:.2f} (limit {cfl_max:.3f} for {self.ndim}D)")

        # Sensor mask
        self._setup_sensor_mask()

        # PML (Perfectly Matched Layer)
        self._setup_pml()

        # K-space operators (one per dimension)
        self._setup_kspace_operators()

        # Physics operators
        self._setup_physics_operators()

        # Source operators
        self._setup_source_operators()

        # Initialize fields
        self._setup_fields()

        self._is_setup = True
        return self

    def _setup_sensor_mask(self):
        """Build self._extract(field) → sensor values."""
        xp = self.xp

        mask_raw = _attr(self.sensor, 'mask', None)
        grid_numel = int(np.prod(self.grid_shape))

        def _is_binary(arr):
            """numel matches grid → boolean mask (matches MATLAB isCartesian logic)."""
            return arr.size == 1 or arr.size == grid_numel

        def _is_cartesian(arr):
            """First dimension matches ndim, remaining are query points."""
            return arr.ndim == 2 and arr.shape[0] == self.ndim

        if mask_raw is None:
            self.n_sensor_points = grid_numel
            self._extract = lambda f: f.flatten(order="F")
        else:
            mask_arr = np.asarray(mask_raw, dtype=float)
            if _is_binary(mask_arr):
                bmask = xp.array(mask_arr, dtype=bool).flatten(order="F")
                if bmask.size == 1:
                    bmask = xp.full(grid_numel, bool(bmask[0]), dtype=bool)
                self.n_sensor_points = int(xp.sum(bmask))
                idx = xp.where(bmask)[0]
                self._extract = lambda f, _i=idx: f.flatten(order="F")[_i]
            elif _is_cartesian(mask_arr):
                self._setup_cartesian_extract(mask_arr)
            else:
                raise ValueError(
                    f"Sensor mask shape {mask_arr.shape} is neither binary "
                    f"(numel={grid_numel}) nor Cartesian ({self.ndim}, N_points)"
                )

        # Parse sensor.record
        record = _attr(self.sensor, 'record', ('p',))
        if isinstance(record, str): record = (record,)
        self.record = set(record)
        if 'u' in self.record:
            self.record.discard('u')
            self.record.update(f'u{a}' for a in 'xyz'[:self.ndim])
        if 'u_staggered' in self.record:
            self.record.discard('u_staggered')
            self.record.update(f'u{a}_staggered' for a in 'xyz'[:self.ndim])

        # Expand shorthand velocity keys: u_max → ux_max, uy_max, uz_max
        for suffix in ('_max', '_min', '_rms', '_final'):
            if f'u{suffix}' in self.record:
                self.record.discard(f'u{suffix}')
                self.record.update(f'u{a}{suffix}' for a in 'xyz'[:self.ndim])

        # Expand aggregate keys → ensure base time-series is recorded
        for key in list(self.record):
            for suffix in ('_max', '_min', '_rms'):
                if key.endswith(suffix):
                    self.record.add(key[:-len(suffix)])  # p_rms → p, ux_max → ux

        # Intensity requires both p and u time-series
        if 'I' in self.record or 'I_avg' in self.record:
            self.record.update(['p'] + [f'u{a}' for a in 'xyz'[:self.ndim]])
        if 'I' in self.record:
            self.record.discard('I')
            self.record.update(f'I{a}' for a in 'xyz'[:self.ndim])
        if 'I_avg' in self.record:
            self.record.discard('I_avg')
            self.record.update(f'I{a}_avg' for a in 'xyz'[:self.ndim])

        # MATLAB uses 1-based indexing; convert to Python's 0-based for array slicing
        record_start_raw = _attr(self.sensor, 'record_start_index', 1)
        self.record_start_index = int(record_start_raw) - 1
        self.num_recorded_time_points = self.Nt - self.record_start_index

    def _setup_cartesian_extract(self, cart_pos):
        """Build self._extract using bilinear/trilinear interpolation on the regular grid."""
        xp = self.xp
        cart = cart_pos if cart_pos.ndim == 2 else cart_pos.reshape(self.ndim, -1)
        self.n_sensor_points = cart.shape[1]

        # Reconstruct kWaveGrid coordinate axes (centered at origin)
        axis_coords = [(np.arange(N) - N // 2) * d for N, d in zip(self.dims, self.spacing)]

        if self.ndim == 1:
            x_vec, cart_x = axis_coords[0], cart.flatten()
            def _extract_1d_interp(f):
                return xp.asarray(np.interp(cart_x, x_vec, _to_cpu(f).flatten(order="F")))
            self._extract = _extract_1d_interp
        else:
            # Convert Cartesian positions to continuous grid indices
            frac_idx = np.array([(cart[d] - axis_coords[d][0]) / self.spacing[d]
                                 for d in range(self.ndim)])  # (ndim, n_pts)
            int_idx = np.clip(np.floor(frac_idx).astype(int), 0,
                              np.array(self.dims)[:, None] - 2)
            local = frac_idx - int_idx

            # F-order strides and 2^ndim corner enumeration
            strides = np.cumprod([1] + list(self.dims[:-1]))
            n_corners = 2 ** self.ndim
            corner_indices = np.zeros((self.n_sensor_points, n_corners), dtype=int)
            corner_weights = np.ones((self.n_sensor_points, n_corners))
            for c in range(n_corners):
                for d in range(self.ndim):
                    bit = (c >> d) & 1
                    corner_indices[:, c] += (int_idx[d] + bit) * strides[d]
                    corner_weights[:, c] *= local[d] if bit else (1 - local[d])

            corner_indices = xp.array(corner_indices)
            corner_weights = xp.array(corner_weights)
            def _extract_bilinear(f):
                return (f.flatten(order="F")[corner_indices] * corner_weights).sum(axis=1)
            self._extract = _extract_bilinear

    def _setup_pml(self):
        """Build Perfectly Matched Layer absorption operators for each dimension."""
        xp = self.xp
        axis_names = ['x', 'y', 'z']

        self.pml_list = []      # For pressure/density
        self.pml_sg_list = []   # For velocity (staggered grid)
        self.pml_sizes = []     # PML thickness per axis (for interior slicing)

        for axis in range(self.ndim):
            N = self.dims[axis]
            dx = self.spacing[axis]
            name = axis_names[axis]

            pml_size = int(_attr(self.kgrid, f'pml_size_{name}', 0))
            pml_alpha = float(_attr(self.kgrid, f'pml_alpha_{name}', 0))
            self.pml_sizes.append(pml_size if pml_alpha != 0 else 0)

            if pml_size == 0 or pml_alpha == 0:
                # No PML for this dimension - use identity (multiply by 1)
                shape = [1] * self.ndim
                shape[axis] = N
                self.pml_list.append(xp.ones(shape, dtype=float))
                self.pml_sg_list.append(xp.ones(shape, dtype=float))
            else:
                # Build PML profile: exp(-alpha * (c/dx) * (x/pml_size)^4 * dt/2)
                x = xp.arange(1, pml_size + 1, dtype=float)

                # Regular grid (for pressure/density)
                pml_left = pml_alpha * (self.c_ref / dx) * ((x - pml_size - 1) / (-pml_size))**4
                pml_right = pml_alpha * (self.c_ref / dx) * (x / pml_size)**4

                # Staggered grid (for velocity)
                pml_left_sg = pml_alpha * (self.c_ref / dx) * ((x + 0.5 - pml_size - 1) / (-pml_size))**4
                pml_right_sg = pml_alpha * (self.c_ref / dx) * ((x + 0.5) / pml_size)**4

                # Exponentiate
                pml_left = xp.exp(-pml_left * self.dt / 2)
                pml_right = xp.exp(-pml_right * self.dt / 2)
                pml_left_sg = xp.exp(-pml_left_sg * self.dt / 2)
                pml_right_sg = xp.exp(-pml_right_sg * self.dt / 2)

                # Assemble full PML profile (1 in interior)
                pml = xp.ones(N, dtype=float)
                pml[:pml_size] = pml_left
                pml[-pml_size:] = pml_right

                pml_sg = xp.ones(N, dtype=float)
                pml_sg[:pml_size] = pml_left_sg
                pml_sg[-pml_size:] = pml_right_sg

                # Reshape for broadcasting
                shape = [1] * self.ndim
                shape[axis] = N
                self.pml_list.append(pml.reshape(shape))
                self.pml_sg_list.append(pml_sg.reshape(shape))

    def _setup_kspace_operators(self):
        """Build k-space gradient/divergence operators for each dimension."""
        xp = self.xp
        self.k_list = []

        # First pass: build k-vectors for each dimension
        for axis, (N, dx) in enumerate(zip(self.dims, self.spacing)):
            k = 2 * np.pi * xp.fft.fftfreq(N, d=dx)
            shape = [1] * self.ndim
            shape[axis] = N
            self.k_list.append(k.reshape(shape))

        # |k| = sqrt(kx^2 + ky^2 + ...) — must use full N-D magnitude for isotropic dispersion
        k_mag_sq = self.k_list[0]**2
        for k in self.k_list[1:]:
            k_mag_sq = k_mag_sq + k**2
        k_mag = xp.sqrt(k_mag_sq)

        # k-space correction: kappa = sin(omega*dt/2) / (omega*dt/2) where omega = c_ref*|k|
        # MATLAB: sinc(A) = sin(pi*A)/(pi*A), so sinc(c*k*dt/2) gives sin(pi*A)/(pi*A)
        # NumPy:  sinc(x) = sin(pi*x)/(pi*x), so sinc(A/pi) gives sin(A)/A ← correct
        # Both evaluate the unnormalized sinc of omega*dt/2 (Tabei et al., JASA 2002, Eq. 10)
        self.kappa = xp.sinc((self.c_ref * k_mag * self.dt / 2) / np.pi)

        # Source kappa: cos correction for time-varying sources (Cox et al., IEEE IUS 2018)
        self.source_kappa = xp.cos(self.c_ref * k_mag * self.dt / 2)

        # Per-dimension operators handle staggered grid shifts; kappa applied globally
        self.op_grad_list = []
        self.op_div_list = []
        for axis, (N, dx) in enumerate(zip(self.dims, self.spacing)):
            k = self.k_list[axis]
            self.op_grad_list.append(1j * k * xp.exp( 1j * k * dx/2))
            self.op_div_list.append(1j * k * xp.exp(-1j * k * dx/2))

    def _setup_physics_operators(self):
        """Build absorption, dispersion, and nonlinearity operators."""
        xp = self.xp

        # Absorption/dispersion
        alpha_coeff_raw = _attr(self.medium, 'alpha_coeff', 0)
        if not _is_enabled(alpha_coeff_raw):
            self._absorption = lambda div_u: 0
            self._dispersion = lambda rho: 0
        else:
            alpha_coeff = _expand_to_grid(alpha_coeff_raw, self.grid_shape, xp, "alpha_coeff")
            alpha_power = float(xp.array(_attr(self.medium, 'alpha_power', 1.5)).flatten()[0])
            alpha_np = 100 * alpha_coeff * (1e-6 / (2 * np.pi))**alpha_power / (20 * np.log10(np.e))

            if abs(alpha_power - 2.0) < 1e-10:  # Stokes
                self._absorption = lambda div_u: -2 * alpha_np * self.c0 * self.rho0 * div_u
                self._dispersion = lambda rho: 0
            else:  # Power-law with fractional Laplacian
                tau = -2 * alpha_np * self.c0**(alpha_power - 1)
                eta = 2 * alpha_np * self.c0**alpha_power * xp.tan(np.pi * alpha_power / 2)
                nabla1 = self._fractional_laplacian(alpha_power - 2)
                nabla2 = self._fractional_laplacian(alpha_power - 1)
                # Fractional Laplacian already includes full k-space structure; no kappa needed
                self._absorption = lambda div_u: tau * self._diff(self.rho0 * div_u, nabla1, apply_kappa=False)
                self._dispersion = lambda rho: eta * self._diff(rho, nabla2, apply_kappa=False)

        # Nonlinearity
        BonA_raw = _attr(self.medium, 'BonA', 0)
        if not _is_enabled(BonA_raw):
            self._nonlinearity = lambda rho: 0
            self._nonlinear_factor = lambda rho: 1.0
        else:
            BonA = _expand_to_grid(BonA_raw, self.grid_shape, xp, "BonA")
            self._nonlinearity = lambda rho: BonA * rho**2 / (2 * self.rho0)
            self._nonlinear_factor = lambda rho: (2*rho + self.rho0) / self.rho0

    def _setup_source_operators(self):
        """Build time-varying source injection operators.

        Source scaling follows kspaceFirstOrder_scaleSourceTerms.m.

        Pressure sources are injected as mass sources into the split density
        fields (rho_x, rho_y, ...).  Since p = c0^2 * (rho_x + rho_y + ...),
        the user-supplied pressure must be converted to density and divided
        equally across N = ndim components:

            dirichlet:  source.p / (N * c0^2)
            additive:   source.p * 2*dt / (N * c0 * dx)

        The 1/c0^2 converts pressure to density (equation of state).
        The 1/N splits evenly so the sum reconstructs the correct total.
        The 2*dt/(c0*dx) factor accounts for the leapfrog time discretization
        (see Cox et al., IEEE IUS 2018).

        Velocity sources use per-axis grid spacing (dx, dy, dz):

            additive:   source.ux * 2*c0*dt / dx   (and dy for uy, dz for uz)
        """
        xp = self.xp
        grid_size = int(np.prod(self.grid_shape))

        def build_op(mask_raw, signal_raw, mode, scale):
            """Build a source injection operator for one field variable."""
            if not (_is_enabled(mask_raw) and _is_enabled(signal_raw)):
                return None

            mask = xp.array(mask_raw, dtype=bool).flatten(order="F")
            if mask.size == 1:
                mask = xp.full(self.grid_shape, bool(mask[0]), dtype=bool).flatten(order="F")
            n_src = int(xp.sum(mask))

            signal_arr = xp.array(signal_raw, dtype=float, order="F")
            if signal_arr.ndim == 1:
                signal = signal_arr.reshape(1, -1)
            else:
                signal = signal_arr.reshape(-1, signal_arr.shape[-1], order="F") if signal_arr.ndim > 2 else signal_arr

            scaled = signal * xp.atleast_1d(xp.asarray(scale))[:, None]

            def get_val(t):
                if scaled.shape[0] == 1:
                    return xp.full(n_src, float(scaled[0, t]))
                return scaled[:, t]

            def dirichlet(t, field):
                flat = field.flatten(order="F")
                flat[mask] = get_val(t)
                return flat.reshape(self.grid_shape, order="F")

            def additive_kspace(t, field):
                src = xp.zeros(grid_size, dtype=field.dtype)
                src[mask] = get_val(t)
                src = src.reshape(self.grid_shape, order="F")
                return field + self._diff(src, self.source_kappa, apply_kappa=False)

            def additive_no_correction(t, field):
                flat = field.flatten(order="F")
                flat[mask] += get_val(t)
                return flat.reshape(self.grid_shape, order="F")

            ops = {"dirichlet": dirichlet, "additive": additive_kspace}
            return ops.get(mode, additive_no_correction)

        def source_scale(mask_raw, c0):
            """Get per-source-point sound speed values."""
            mask = xp.array(mask_raw, dtype=bool).flatten(order="F")
            if mask.size == 1:
                mask = xp.full(self.grid_shape, bool(mask[0]), dtype=bool).flatten(order="F")
            c0_flat = c0.flatten(order="F")
            n_src = int(xp.sum(mask))
            return c0_flat[mask] if c0_flat.size > 1 else xp.full(n_src, float(c0_flat))

        # --- Pressure source ---
        p_mask = _attr(self.source, 'p_mask', 0)
        p_signal = _attr(self.source, 'p', 0)
        p_mode = _attr(self.source, 'p_mode', 'additive')
        N = self.ndim
        if _is_enabled(p_mask) and _is_enabled(p_signal):
            c0_src = source_scale(p_mask, self.c0)
            dx = self.spacing[0]
            if p_mode == "dirichlet":
                # rho_i = source.p / (N * c0^2)
                scale = 1.0 / (N * c0_src**2)
            else:
                # rho_i += source.p * 2*dt / (N * c0 * dx)
                scale = 2 * self.dt / (N * c0_src * dx)
            op = build_op(p_mask, p_signal, p_mode, scale)
            self._source_p_op = lambda t, field, dim, _op=op: _op(t, field)
        else:
            self._source_p_op = lambda t, field, dim: field

        # --- Velocity sources (per-axis grid spacing) ---
        u_mask = _attr(self.source, 'u_mask', 0)
        u_mode = _attr(self.source, 'u_mode', 'additive')
        self._source_u_ops = []
        for i, vel in enumerate(['ux', 'uy', 'uz'][:self.ndim]):
            u_signal = _attr(self.source, vel, 0)
            di = self.spacing[i]  # dx for ux, dy for uy, dz for uz
            if _is_enabled(u_mask) and _is_enabled(u_signal):
                c0_src = source_scale(u_mask, self.c0)
                if u_mode == "dirichlet":
                    scale = xp.ones_like(c0_src)
                else:
                    # u_i += source.u_i * 2*c0*dt / d_i
                    scale = 2 * c0_src * self.dt / di
                op = build_op(u_mask, u_signal, u_mode, scale)
                self._source_u_ops.append(op)
            else:
                self._source_u_ops.append(lambda t, field: field)

    def _setup_fields(self):
        """Initialize pressure, velocity, and density fields."""
        xp = self.xp

        self.p = xp.zeros(self.grid_shape, dtype=float)
        self.u = [xp.zeros(self.grid_shape, dtype=float) for _ in range(self.ndim)]
        # Split density per dimension enables independent PML absorption in each direction
        self.rho_split = [xp.zeros(self.grid_shape, dtype=float) for _ in range(self.ndim)]

        # Staggered density for each dimension
        self.rho0_staggered = [self._stagger(self.rho0, axis) for axis in range(self.ndim)]

        # Sensor data storage (sized based on record_start_index)
        self.sensor_data = {}
        if 'p' in self.record:
            self.sensor_data['p'] = xp.zeros((self.n_sensor_points, self.num_recorded_time_points), dtype=float)
        for a in 'xyz'[:self.ndim]:
            for suffix in ('', '_staggered'):
                v = f'u{a}{suffix}'
                if v in self.record:
                    self.sensor_data[v] = xp.zeros((self.n_sensor_points, self.num_recorded_time_points), dtype=float)

        # Spectral shift: move velocity from staggered (mid-cell) to collocated (pressure) grid
        if any(f'u{a}' in self.sensor_data for a in 'xyz'[:self.ndim]):
            self.unstagger_ops = [xp.exp(-1j * self.k_list[ax] * self.spacing[ax] / 2)
                                  for ax in range(self.ndim)]

        # Initial pressure source (p0)
        p0_raw = _attr(self.source, 'p0', 0)
        self._p0_initial = _expand_to_grid(p0_raw, self.grid_shape, xp, "p0") if _is_enabled(p0_raw) else None

        # Initialize velocity at t=-dt/2 for leapfrog
        for i in range(self.ndim):
            self.u[i] += (self.dt / (2 * self.rho0_staggered[i])) * self._diff(self.p, self.op_grad_list[i])

    def step(self):
        """Advance simulation by one time step. Returns self for chaining."""
        if not self._is_setup:
            self.setup()
        if self.t >= self.Nt:
            return self

        xp = self.xp

        # Momentum equation: du_i/dt = -grad_i(p)/rho, with PML
        for i in range(self.ndim):
            pml_sg = self.pml_sg_list[i]
            # Double PML application implements second-order absorption (split-field PML)
            self.u[i] = pml_sg * (pml_sg * self.u[i]
                - (self.dt / self.rho0_staggered[i]) * self._diff(self.p, self.op_grad_list[i]))
            self.u[i] = self._source_u_ops[i](self.t, self.u[i])

        # Mass conservation: drho_i/dt = -rho0 * div_i(u_i), with PML
        rho_total = sum(self.rho_split)
        div_u_components = []
        for i in range(self.ndim):
            pml = self.pml_list[i]
            div_u_i = self._diff(self.u[i], self.op_div_list[i])
            div_u_components.append(div_u_i)
            # Double PML application implements second-order absorption (split-field PML)
            self.rho_split[i] = pml * (pml * self.rho_split[i]
                - self.dt * self.rho0 * div_u_i * self._nonlinear_factor(rho_total))
            self.rho_split[i] = self._source_p_op(self.t, self.rho_split[i], i)

        # Equation of state
        rho_total = sum(self.rho_split)
        div_u_total = sum(div_u_components)
        self.p = self.c0**2 * (rho_total + self._absorption(div_u_total)
                               - self._dispersion(rho_total) + self._nonlinearity(rho_total))

        # At t=0, override equation of state with p0; reset split densities and u(-dt/2) for leapfrog
        if self.t == 0 and self._p0_initial is not None:
            self.p = self._p0_initial.copy()
            for i in range(self.ndim):
                self.rho_split[i] = self._p0_initial / (self.c0**2 * self.ndim)
                self.u[i] = (self.dt / (2 * self.rho0_staggered[i])) * self._diff(self.p, self.op_grad_list[i])

        # Record sensor data (binary: index extraction, Cartesian: Delaunay interpolation)
        if self.t >= self.record_start_index:
            file_index = self.t - self.record_start_index
            if 'p' in self.sensor_data:
                self.sensor_data['p'][:, file_index] = self._extract(self.p)
            for i, a in enumerate('xyz'[:self.ndim]):
                if f'u{a}' in self.sensor_data:  # colocated
                    shifted = xp.real(xp.fft.ifftn(self.unstagger_ops[i] * xp.fft.fftn(self.u[i])))
                    self.sensor_data[f'u{a}'][:, file_index] = self._extract(shifted)
                if f'u{a}_staggered' in self.sensor_data:  # raw staggered
                    self.sensor_data[f'u{a}_staggered'][:, file_index] = self._extract(self.u[i])
        self.t += 1
        return self

    def run(self):
        """Run simulation to completion. Returns results dict."""
        if not self._is_setup:
            self.setup()
        while self.t < self.Nt:
            self.step()
        result = {k: _to_cpu(v) for k, v in self.sensor_data.items()}
        result.update(_compute_aggregates(result, self.ndim))
        if 'p' in result and any(f'u{a}' in result for a in 'xyz'):
            result.update(acoustic_intensity(result))
        # Final-state snapshots: interior grid (excluding PML) at last timestep
        interior = tuple(slice(s, N - s if s else None) for s, N in zip(self.pml_sizes, self.grid_shape))
        if 'p_final' in self.record:
            result['p_final'] = _to_cpu(self.p[interior].copy())
        if any(f'u{a}_final' in self.record for a in 'xyz'):
            for i, a in enumerate('xyz'[:self.ndim]):
                if f'u{a}_final' in self.record:
                    result[f'u{a}_final'] = _to_cpu(self.u[i][interior].copy())
        return {k: v for k, v in result.items() if k in self.record}

    # Helper methods
    def _diff(self, f, op, apply_kappa=True):
        """Spectral differentiation: F^-1[op * kappa * F[f]]."""
        # TODO: rfftn/irfftn for ~2x speedup on real fields (requires half-grid k-space operators)
        xp = self.xp
        kappa = self.kappa if apply_kappa else 1
        return xp.real(xp.fft.ifftn(op * kappa * xp.fft.fftn(f)))

    def _stagger(self, arr, axis):
        """Compute staggered grid values (average neighbors along axis)."""
        if arr.size == 1: return arr
        xp = self.xp
        lo = [slice(None)] * arr.ndim
        hi = [slice(None)] * arr.ndim
        lo[axis], hi[axis] = slice(None, -1), slice(1, None)
        avg = 0.5 * (arr[tuple(lo)] + arr[tuple(hi)])
        last = [slice(None)] * arr.ndim
        last[axis] = slice(-1, None)
        return xp.concatenate([avg, arr[tuple(last)]], axis=axis)

    def _fractional_laplacian(self, power):
        """N-D fractional Laplacian |k|^power."""
        xp = self.xp
        k_mag_sq = sum(xp.fft.fftshift(k)**2 for k in self.k_list)
        k_mag = xp.sqrt(k_mag_sq)
        # Suppress NumPy warnings at k=0 singularity (CuPy doesn't raise these)
        with np.errstate(divide='ignore', invalid='ignore'):
            return xp.fft.ifftshift(xp.where(k_mag == 0, 0, k_mag**power))

# =============================================================================
# Post-Processing
# =============================================================================

def _compute_aggregates(result, ndim):
    """Compute max/min/rms from time-series. Returns only computed keys."""
    out = {}
    for prefix in ['p'] + [f'u{a}' for a in 'xyz'[:ndim]]:
        ts = result.get(prefix)
        if ts is None:
            continue
        out[f'{prefix}_max'] = np.max(ts, axis=-1)
        out[f'{prefix}_min'] = np.min(ts, axis=-1)
        out[f'{prefix}_rms'] = np.sqrt(np.mean(ts ** 2, axis=-1))
    return out

def acoustic_intensity(result):
    """Compute acoustic intensity from simulation result dict.

    Temporally shifts velocity forward by dt/2 (Fourier interpolant)
    to align with pressure, then computes I = p * u per component.

    Returns dict with Ix, Iy, Iz, Ix_avg, Iy_avg, Iz_avg.
    """
    p = result['p']
    n_time = p.shape[-1]
    freq = 2 * np.pi * np.arange(-(n_time // 2), n_time - n_time // 2) / n_time
    freq[n_time // 2] = 0  # zero Nyquist to avoid aliasing artifacts
    shift_op = np.fft.ifftshift(np.exp(1j * freq * 0.5))

    out = {}
    for a in 'xyz':
        u = result.get(f'u{a}')
        if u is None:
            break
        u_shifted = np.real(np.fft.ifft(shift_op * np.fft.fft(u, axis=-1), axis=-1))
        out[f'I{a}'] = p * u_shifted
        out[f'I{a}_avg'] = np.mean(p * u_shifted, axis=-1)
    return out

# =============================================================================
# MATLAB Interop
# =============================================================================

def _to_namespace(d):
    """Convert dict to SimpleNamespace."""
    return SimpleNamespace(**dict(d))

# MATLAB code uses both c0/sound_speed and rho0/density; normalize to canonical names
def _normalize_medium(m):
    d = dict(m)
    if 'c0' in d and 'sound_speed' not in d: d['sound_speed'] = d.pop('c0')
    if 'rho0' in d and 'density' not in d: d['density'] = d.pop('rho0')
    return d

def create_simulation(kgrid, medium, source, sensor, backend="auto"):
    """MATLAB interop: create Simulation from dicts (for step-by-step debugging)."""
    return Simulation(
        _to_namespace(kgrid),
        _to_namespace(_normalize_medium(medium)),
        _to_namespace(source),
        _to_namespace(sensor),
        backend
    )

def simulate_from_dicts(kgrid, medium, source, sensor, backend="auto"):
    """MATLAB interop entry point."""
    return create_simulation(kgrid, medium, source, sensor, backend).run()

def interop_sanity(arr):
    """Verify MATLAB/Python data layout."""
    a = np.array(arr, copy=True)
    a[0, 1] = 99
    return a
